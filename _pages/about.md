---
permalink: /
title: ""
excerpt: ""
author_profile: true
redirect_from: 
  - /about/
  - /about.html
---

{% if site.google_scholar_stats_use_cdn %}
{% assign gsDataBaseUrl = "https://cdn.jsdelivr.net/gh/" | append: site.repository | append: "@" %}
{% else %}
{% assign gsDataBaseUrl = "https://raw.githubusercontent.com/" | append: site.repository | append: "/" %}
{% endif %}
{% assign url = gsDataBaseUrl | append: "google-scholar-stats/gs_data_shieldsio.json" %}

<span class='anchor' id='about-me'></span>

I am a Phd Candidate of ***R&L Group at Nanjing University (NJU)***, under the supervision of Prof. ***Qi Fan*** [-- homepage](https://fanq15.github.io/). I obtained my M.S. in Computer Science at ***the University of Chinese Academy of Sciences*** in 2024 and B.S at ***Shanghai Jiao Tong University*** in 2021. I was also fortunate to be an internship at 01AI, Huawei.

My research interests lie in the intersection of ***Computer Vision and Machine Learning***. From 2021, I started to do some research on Neural architecture search and image caption. Now, I focus on designing novel applications for ***image/video generation, 3D autoregressive-generation*** and other downstream AIGC tasks. Welcome to the [Zhihu homepage](https://zhuanlan.zhihu.com/p/10593629023) for academic discussions in the field of image/video generation.

# ğŸ“– Educations
- *2024.10 - up-to-now, Phd, School of Intelligence Science and Technology,*  ***Nanjing University.*** <img src="./images/nju_1em.png" style="height: 1em; vertical-align: text-bottom; object-fit: contain;">
- *2021.09 - 2024.06, M.S.  degree, School of Computer Science and Technology,* ***University of Chinese Academy of Sciences.*** <img src="./images/ucas_1em.png" style="height: 1em; vertical-align: text-bottom; object-fit: contain;">
- *2017.09 - 2021.06, B.S.  degree, School of Electronic Information and Electrical Engineering,* ***Shanghai Jiao Tong University.*** <img src="./images/sjtu_1em.png" style="height: 1em; vertical-align: text-bottom; object-fit: contain;">

# ğŸ‰ News
- *2025.05*: &nbsp;ğŸ“ğŸ“ I joined 
  <img src="./Kuaishou_icon.png" style="height: 1em; vertical-align: text-bottom; object-fit: contain;">
  <img src="./Kling_icon.png" style="height: 1em; vertical-align: text-bottom; object-fit: contain;">
  **Kuaishou-Kling**, Basic Visual Generation Group, as a research intern.
- *2025.05*: &nbsp;ğŸ“ğŸ“ I joined
  <img src="./teleai_icon.png" style="height: 1em; vertical-align: text-bottom; object-fit: contain;">
  **TeleAI**, Video Generation Group, as a research intern.
- *2024.12*: &nbsp;ğŸ‰ğŸ‰ One paper accepted to **AAAI 2025**.
- *2024.09*: &nbsp;ğŸ“ğŸ“ I joined
  <img src="./huawei_icon.png" style="height: 1em; vertical-align: text-bottom; object-fit: contain;">
  **Huawei**, 3D Generation Group, as a researcher.
- *2024.01*: &nbsp;ğŸ‰ğŸ‰ One paper accepted to **AISTATS 2024**.

# ğŸ“ Publications 
- <span class="paperidx">AAAI 2025</span> [ReMask-Animate: Refined Character Image Animation Using Mask-Guided Adapters](https://xbxsxp9.github.io/). <font color=blue><strong><em>Xunzhi Xiang</em></strong></font>, Haiwei Xue, Zonghong Dai, et al. 
- <span class="paperidx">AISTATS 2024</span> [A Neural Architecture Predictor based on GNN-Enhanced Transformer](https://xbxsxp9.github.io/). <font color=blue><strong><em>Xunzhi Xiang</em></strong></font>
, Kun Jing, Jungang Xu, et al.
  
# ğŸ”¥ Preprints 
- <span class="paperidx">ArXiv 2025</span> [Make It Efficient: Dynamic Sparse Attention for Autoregressive Image Generation](https://xbxsxp9.github.io/). <font color=blue><strong><em>Xunzhi Xiang</em></strong></font>, Qi Fan.
- <span class="paperidx">ArXiv 2025</span> [SmartSAM: Segment Ambiguious Objects like Smart Annotaters](https://xbxsxp9.github.io/). Zhe Gao, <font color=blue><strong><em>Xunzhi Xiang</em></strong></font>, Siyu Shen, Wenbin Li, Yang Gao, Qi Fan.
- <span class="paperidx">ArXiv 2025</span> [DONâ€™T NEED RETRAINING: A Mixture of DETR and Vision Foundation Models for Cross-Domain Few-Shot Object Detection](https://xbxsxp9.github.io/). Chang-han Li, <font color=blue><strong><em>Xunzhi Xiang</em></strong></font>, Zixuan Duan, Wenbin Li, Yang Gao, Qi Fan.
- <span class="paperidx">ArXiv 2025</span> [Proteus-ID: ID-Consistent and Motion-Enhanced Video Customization](https://xbxsxp9.github.io/). Guiyu Zhang, Chen Shi, Zijian Jiang, <font color=blue><strong><em>Xunzhi Xiang</em></strong></font>, Jingjing Qian, Shaoshuai Shi, Li Jiang.
- <span class="paperidx">ArXiv 2024</span> [DPD: A Dual Prompt Distillation Method for Vision-Language Models](https://xbxsxp9.github.io/). Di Wang, <font color=blue><strong><em>Xunzhi Xiang</em></strong></font>, Yiyu Wang, Jungang Xu.
- <span class="paperidx">TPAMI 2025</span> [Human Motion Video Generation: A Survey](https://xbxsxp9.github.io/). Haiwei Xue, Xiangyang Luo, Zhannghao Hu, Xin Zhang, <font color=blue><strong><em>Xunzhi Xiang</em></strong></font>, Yuqing dai, Jianzhuang Liu, Zhensong Zhang, Minglei Li, Jian Yang, Fei Ma, Changpeng Yang, Zonghong Dai, and Fei Richard Yu.

# ğŸ’» Internships
- *2024.03 - 2024.09*, [01AI](https://www.lingyiwanwu.com/), China.
- *2024.03 - 2024.09*, [Guangming-Lab](https://www.gml.ac.cn/), China.
- *2024.09 - 2025.03*, [HUAWEI](https://github.com/), China.
- *2025.05 - up-to-now*, [Kuaishou-Kling](https://github.com/), China.
- *2025.05 - up-to-now*, [TeleAI](https://github.com/), China.

# ğŸ– Honors and Awards
- *2021.10* Lorem ipsum dolor sit amet, consectetur adipiscing elit. Vivamus ornare aliquet ipsum, ac tempus justo dapibus sit amet. 
- *2021.09* Lorem ipsum dolor sit amet, consectetur adipiscing elit. Vivamus ornare aliquet ipsum, ac tempus justo dapibus sit amet. 

